{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trip Duration Prediction\n",
    "*By Michael Florip, Spring 2024*\n",
    "\n",
    "**Project Goal**\n",
    "The goal of this project is to explore use cases of telematics data using the *v2x_columbus_trips/v2x_columbus_trips_summary_clean* dataset provided by the 99P Labs team at the Honda Research Institute USA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore overall dataset\n",
    "df = pd.read_csv(\"/Users/michaelflorip/Desktop/Berkeley/hri99p/v2x_columbus_trips/v2x_columbus_trips_summary_clean.csv\", encoding='ascii')\n",
    "print(df.head())\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations and Potential Predictive Modeling Ideas\n",
    "\n",
    "**Temporal Data**\n",
    "The dataset contains several time-related fields (timestamp, startlocaltime, endlocaltime). These could be used to predict traffic patterns or trip durations.\n",
    "\n",
    "**Geospatial Data**\n",
    "Latitude and longitude fields (startlatitude, startlongitude, endlatitude, endlongitude) are present, which could be useful for predicting trip destinations or analyzing spatial patterns.\n",
    "\n",
    "**Vehicle and Trip Metrics** \n",
    "Fields like numbsmtx (number of BSM transmissions), numnormalbsmrx (number of normal BSM receptions), and numintersectionencounters could be used to predict vehicle behavior or safety-related metrics.\n",
    "\n",
    "**Device and Configuration**\n",
    "Fields like device, firmwareversionstring, and configsversionstring might be useful for predicting device performance or maintenance needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Project Scopes\n",
    "**Predicting Trip Duration**\n",
    "Use start and end times to predict the duration of trips. This could be useful for route planning and traffic management.\n",
    "\n",
    "**Predicting Destination**\n",
    "Use starting coordinates and other trip data to predict the end coordinates. This could be useful for navigation and ride-sharing applications.\n",
    "\n",
    "**Predicting Vehicle Performance Metrics**\n",
    "Use device data and trip metrics to predict performance-related outcomes like fuel efficiency or maintenance needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive Modeling Options\n",
    "**Regression Model**\n",
    "If predicting a continuous variable like trip duration or fuel efficiency\n",
    "\n",
    "**Classification Model**\n",
    "If predicting categorical outcomes like whether a trip will encounter a certain number of intersections or safety incidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game Plan for Model Creation\n",
    "**Data Preparation**\n",
    "* Convert *startlocaltime* and *endlocaltime* from their current format to a more useable datetime format\n",
    "* Calculate the trip duration by simply subtracting *startlocaltime* from *endlocaltime*\n",
    "* Handle any missing or erroneous data\n",
    "\n",
    "**Feature Selection**\n",
    "* Decide on which features might influence trip duration\n",
    "* Potential features include: *startlatitude*, *startlongitude*, *endlatitude*, *endlongitude*, *timestamp*, *filedate*, *device*, *firmwareversionstring*\n",
    "* Create new features if necessary (example: time of day from *timestamp*)\n",
    "\n",
    "**Model Selection**\n",
    "Since trip duration is a continuous variable, I will take a regression approach. Potential models include:\n",
    "* Linear regression\n",
    "* Decision Tree regressor\n",
    "* Random Forest regressor\n",
    "* Gradient Boosting machines\n",
    "\n",
    "**Model Training**\n",
    "* Split the data into training and testing sets (80/20 split)\n",
    "* Train the model on the training set\n",
    "\n",
    "**Model Evaluation**\n",
    "* Evaluate the model on the testing set using metrics such as Mean Absolute Error (MAE), Mean Square Error (MSE), or Root Mean Square Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamps to datetime\n",
    "try:\n",
    "    df['startlocaltime'] = pd.to_datetime(df['startlocaltime'], unit='ms')\n",
    "    df['endlocaltime'] = pd.to_datetime(df['endlocaltime'], unit='ms')\n",
    "except Exception as e:\n",
    "    print('Error converting to datetime:', e)\n",
    "\n",
    "# Calculate trip duration in minutes\n",
    "try:\n",
    "    df['trip_duration'] = (df['endlocaltime'] - df['startlocaltime']).dt.total_seconds() / 60\n",
    "except Exception as e:\n",
    "    print('Error calculating trip duration:', e)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(df[['startlocaltime', 'endlocaltime', 'trip_duration']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "* The *startlocaltime* and *endlocaltime* have been successfully converted to datetime format\n",
    "* The *trip_duration* column has been added, representing the duration of each trip in minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "**Data Cleaning**\n",
    "Check for any anomalies or outliers in the trip durations, such as extremely long or short trips, which might affect the model's performance\n",
    "\n",
    "**Feature Engineering**\n",
    "Create additional features that might be relevant for predicting trip duration\n",
    "\n",
    "**Model Training**\n",
    "Begin training a simple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for anomalies or outliers in trip durations\n",
    "print('Descriptive statistics for trip duration:\\\n",
    "', df['trip_duration'].describe())\n",
    "\n",
    "# Identify extreme outliers\n",
    "outliers = df[df['trip_duration'] > df['trip_duration'].quantile(0.99)]\n",
    "print('\\\n",
    "Outliers (above 99th percentile):\\\n",
    "', outliers[['trip_duration', 'startlocaltime', 'endlocaltime']].head())\n",
    "\n",
    "# Check for any trips with negative durations (errors)\n",
    "negative_durations = df[df['trip_duration'] < 0]\n",
    "print('\\\n",
    "Negative trip durations (errors):\\\n",
    "', negative_durations[['trip_duration', 'startlocaltime', 'endlocaltime']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "* The mean trip duration is about -5.35 minutes, which suggests there are errors in the data, since trip duration which is in minutes cannot be negative\n",
    "* The standard deviation is quite high, indicating significant variability in trip durations\n",
    "* The minimum trip duration is -1438.49 minutes, confirming that there is erroneous data\n",
    "\n",
    "**Next Steps**\n",
    "* The negative durations are clearly errors and will be removed from the dataset\n",
    "* To handle outliers, I will cap the outliers at the 99th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove negative trip durations\n",
    "df = df[df['trip_duration'] >= 0]\n",
    "print('Removed negative trip durations.')\n",
    "\n",
    "# Cap outliers at the 99th percentile\n",
    "percentile_99 = df['trip_duration'].quantile(0.99)\n",
    "df.loc[df['trip_duration'] > percentile_99, 'trip_duration'] = percentile_99\n",
    "print('Capped outliers at the 99th percentile.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "**Feature Engineering**\n",
    "Create additional features that might be relevant for predicting trip duration\n",
    "\n",
    "**Model Training**\n",
    "Begin training a simple regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based features\n",
    "df['start_hour'] = df['startlocaltime'].dt.hour\n",
    "df['day_of_week'] = df['startlocaltime'].dt.dayofweek\n",
    "\n",
    "print('Added time-based features: start_hour and day_of_week.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-based features have been added to the dataset:\n",
    "* *start_hour*: represents the hour of the day the trip started\n",
    "* *day_of_week*: Indicates the day of the week the trip started (O = Monday, 6 = Sunday)\n",
    "\n",
    "These features can help capture daily and weekly patterns in trip data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "**Data Split for Training & Testing**\n",
    "\n",
    "Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features and target variable\n",
    "X = df[['start_hour', 'day_of_week']]  # Assuming these are the only features for now\n",
    "y = df['trip_duration']\n",
    "\n",
    "# Split the data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Data split into training and testing sets.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choosing a model for regression tasks**\n",
    "* Linear regression: simple and fast\n",
    "* Decision Tree: handles non-linear data well\n",
    "* Random Forest: A more robust version of the decision trees, good for complex data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'Model trained. Mean Squared Error on test set: {mse:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "**Feature Importance Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the model\n",
    "feature_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "\n",
    "# Sort the features by importance\n",
    "sorted_importances = feature_importances.sort_values(ascending=False)\n",
    "\n",
    "print('Feature Importance:\\\n",
    "', sorted_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights**\n",
    "The feature importance analysis from the Random Forest model indicates the following:\n",
    "\n",
    "*start_hour*: This feature has a relative importance of 1.0, suggesting it is the most influential in predicting trip duration.\n",
    "\n",
    "*day_of_week*: This feature has a relative importance of 0.0, indicating it does not significantly impact the prediction of trip duration in the current model setup.\n",
    "\n",
    "Given that *start_hour* is highly influential, it might be beneficial to further explore or engineer additional time-related features or consider other aspects of the data that could enhance the model's predictive power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance**\n",
    "\n",
    "The graph below shows the importance of each feature in predicting trip duration. The *start_hour* has a significantly higher importance compared to *day_of_week*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Feature Importance Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_importances.plot(kind='bar')\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction vs Actual**\n",
    "\n",
    "The below scatter plot compares the actual trip durations against the predicted values from our model. The closer the points are to the dashed line, the more accurate the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs Actual Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.title('Prediction vs Actual')\n",
    "plt.xlabel('Actual Duration')\n",
    "plt.ylabel('Predicted Duration')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "**Model Evaluation**\n",
    "\n",
    "To evaluate the accuracy of our model, we can use the coefficient of determination, commonly known as R² score, which provides an indication of goodness of fit and therefore a measure of how well unseen samples are likely to be predicted by the model. Let's calculate that next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R^2 Score: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R² score for the model is **0.15**. \n",
    "\n",
    "This score indicates that the model explains about 15% of the variance in trip duration based on the current features (start_hour and day_of_week). This suggests that while the model has some predictive power, there is significant room for improvement, possibly by incorporating more relevant features or using more complex modeling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposed Next Steps\n",
    "**Calculate Distance**\n",
    "Use the latitude and longitude to calculate the haversine distance for each trip\n",
    "\n",
    "**Refine Time Features**\n",
    "Create more granular time bins (e.g., morning, afternoon) and possibly consider the effect of holidays\n",
    "\n",
    "**Incorporate Traffic Indicators**\n",
    "Use *numwarnings* and *numinforms* as proxies for traffic conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "# Define a function to calculate the haversine distance between two points on the earth\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Convert decimal degrees to radians \n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula \n",
    "    dlat = lat2 - lat1 \n",
    "    dlon = lon2 - lon1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a)) \n",
    "    km = 6371 * c # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return km\n",
    "\n",
    "# Calculate the distance for each trip\n",
    "df['trip_distance'] = df.apply(lambda x: haversine(x['startlatitude'], x['startlongitude'], x['endlatitude'], x['endlongitude']), axis=1)\n",
    "\n",
    "# Display the head of the dataframe to confirm the new column\n",
    "print(df[['trip_distance']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Insights and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow Summary\n",
    "**Data Preparation and Cleaning**\n",
    "Handled negative and outlier trip durations by removing or capping them, ensuring the data quality for model training\n",
    "\n",
    "**Feature Engineering**\n",
    "* Added time-based features such as *start_hour* and *day_of_week* to capture temporal patterns in trip durations\n",
    "* We calculated the distance of each trip using geographical coordinates, which is a direct factor affecting trip duration\n",
    "\n",
    "**Model Building and Evaluation**\n",
    "* Trained a Random Forest Regressor model that had an R^2 score of **0.15**. This indicates it could explain 15% of the variance in trip durations.\n",
    "* Feature importance analysis showed that the *start_hour* was significantly more important than *day_of_week*, suggesting that the time of day has a greater impact on trip duration\n",
    "\n",
    "**Visual Insights**\n",
    "The feature importance plot highlighted the relative importance of different features in predicting trip duration\n",
    "\n",
    "The prediction vs actual plot provided a visual assessment of the model's performance, showing how close the predictions were to the actual values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations for Further Improvement\n",
    "**Incorporate Additional Features**\n",
    "Including weather conditions, real-time traffic data, and distinguishing between types of days (weekdays vs weekends) could further enhance the model's accuracy\n",
    "\n",
    "**Advanced Modeling Techniques**\n",
    "Trying different algorithms and tuning model parameters could yield better results\n",
    "\n",
    "**Increase Data Size and Quality**\n",
    "This used the *v2x_columbus_trips/v2x_columbus_trips_summary_clean* dataset, which is not the most granular dataset available. I chose this dataset because of the overwhelming size of the full *v2x_columbus_trips* dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
